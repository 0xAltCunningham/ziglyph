// Autogenerated from http://www.unicode.org/Public/UCD/latest/ucd/UCD.zip by running ucd_gen.sh.
//! Unicode decomposition map.

const std = @import("std");
const fmt = std.fmt;
const mem = std.mem;
const sort = std.sort.sort;
const unicode = std.unicode;

const CaseFoldMap = @import("../components/autogen/CaseFolding/CaseFoldMap.zig");
const CccMap = @import("../components/autogen/DerivedCombiningClass/CccMap.zig");
const HangulMap = @import("../components/autogen/HangulSyllableType/HangulMap.zig");
const NFDCheck = @import("../components/autogen/DerivedNormalizationProps/NFDCheck.zig");
const Trieton = @import("../trieton/src/trieton.zig").Trieton;

const DecompTrie = Trieton(u8, Decomposed);
const Lookup = DecompTrie.Lookup;

allocator: *mem.Allocator,
arena: std.heap.ArenaAllocator,
ccc_map: CccMap,
decomp_trie: DecompTrie,
fold_map: CaseFoldMap,
hangul_map: HangulMap,
nfd_check: NFDCheck,

const Self = @This();

/// Decomposed is the result of a code point full decomposition. It can be one of:
/// * .src: Sorce code point.
/// * .same : Default canonical decomposition to the code point itself.
/// * .single : Singleton canonical decomposition to a different single code point.
/// * .canon : Canonical decomposition, which always results in two code points.
/// * .compat : Compatibility decomposition, which can results in at most 18 code points.
pub const Decomposed = union(enum) {
    src: u21,
    same: u21,
    single: u21,
    canon: [2]u21,
    compat: []const u21,
};

pub fn init(allocator: *mem.Allocator, filename: []const u8) !Self {
    var self = Self{
        .allocator = allocator,
        .arena = std.heap.ArenaAllocator.init(allocator),
        .ccc_map = CccMap{},
        .decomp_trie = undefined,
        .fold_map = CaseFoldMap{},
        .hangul_map = HangulMap{},
        .nfd_check = NFDCheck{},
    };

    self.decomp_trie = DecompTrie.init(&self.arena.allocator);

    try self.load(filename);

    return self;
}

pub fn deinit(self: *Self) void {
    self.arena.deinit();
}

var cp_buf: [4]u8 = undefined;

// data/ucd/UnicodeData.txt
fn load(self: *Self, filename: []const u8) !void {
    // Setup input.
    var in_file = try std.fs.cwd().openFile(filename, .{});
    defer in_file.close();
    var buf_reader = std.io.bufferedReader(in_file.reader());
    var input_stream = buf_reader.reader();

    // Iterate over lines.
    var buf: [640]u8 = undefined;

    while (try input_stream.readUntilDelimiterOrEof(&buf, '\n')) |line| {
        // Iterate over fields.
        var fields = mem.split(line, ";");
        var field_index: usize = 0;
        var code_point: []const u8 = undefined;
        while (fields.next()) |raw| : (field_index += 1) {
            if (field_index == 0) {
                // Code point.
                code_point = raw;
            } else if (field_index == 5 and raw.len != 0) {
                // Normalization.
                const parsed_cp = try fmt.parseInt(u21, code_point, 16);
                const key = blk: {
                    const len = try unicode.utf8Encode(parsed_cp, &cp_buf);
                    break :blk cp_buf[0..len];
                };

                var is_compat = false;
                var cp_list = std.ArrayList([]const u8).init(self.allocator);
                defer cp_list.deinit();

                var cp_iter = mem.split(raw, " ");
                while (cp_iter.next()) |cp| {
                    if (mem.startsWith(u8, cp, "<")) {
                        is_compat = true;
                        continue;
                    }
                    try cp_list.append(cp);
                }

                if (!is_compat and cp_list.items.len == 1) {
                    // Singleton
                    const singleton = try fmt.parseInt(u21, cp_list.items[0], 16);
                    try self.decomp_trie.add(key, .{ .single = singleton });
                } else if (!is_compat) {
                    // Canonical
                    std.debug.assert(cp_list.items.len == 2);
                    var canon: [2]u21 = undefined;
                    canon[0] = try fmt.parseInt(u21, cp_list.items[0], 16);
                    canon[1] = try fmt.parseInt(u21, cp_list.items[1], 16);
                    try self.decomp_trie.add(key, .{ .canon = canon });
                } else {
                    // Compatibility
                    std.debug.assert(cp_list.items.len != 0);
                    var compat = std.ArrayList(u21).init(&self.arena.allocator);
                    defer compat.deinit();

                    for (cp_list.items) |ccp| {
                        try compat.append(try fmt.parseInt(u21, ccp, 16));
                    }

                    try self.decomp_trie.add(key, .{ .compat = compat.toOwnedSlice() });
                }
            } else {
                continue;
            }
        }
    }
}

/// mapping retrieves the decomposition mapping for a code point as per the UCD.
pub fn mapping(self: Self, cp: u21) !Decomposed {
    const len = try unicode.utf8Encode(cp, &cp_buf);
    const lookup = self.decomp_trie.find(cp_buf[0..len]);
    if (lookup) |l| {
        if (l.index == len - 1) return l.value;
    }

    return Decomposed{ .same = cp };
}

pub const Form = enum {
    D, // Canonical Decomposition
    KD, // Compatibility Decomposition
};

/// codePointTo takes a code point and returns a sequence of code points that represent its conversion 
/// to the specified Form. Caller must free returned bytes.
pub fn codePointTo(self: Self, allocator: *mem.Allocator, form: Form, cp: u21) anyerror![]u21 {
    if (form == .D and self.nfd_check.isNFD(cp)) {
        var dcp = try allocator.alloc(u21, 1);
        dcp[0] = cp;
        return dcp;
    }

    // Decomposition.
    if (self.isHangulPrecomposed(cp)) {
        // Hangul precomposed syllable full decomposition.
        const dcs = self.decomposeHangul(cp);
        const len: usize = if (dcs[2] == 0) 2 else 3;
        var result = try allocator.alloc(u21, len);
        mem.copy(u21, result, dcs[0..len]);
        return result;
    } else {
        // Non-Hangul code points.
        const src = [1]Decomposed{.{ .src = cp }};
        const dcs = try self.decomposeTo(allocator, form, &src);
        defer allocator.free(dcs);
        var result = try allocator.alloc(u21, dcs.len);
        for (dcs) |dc, index| {
            result[index] = dc.same;
        }
        return result;
    }
}

/// decomposeTo recursively performs decomposition until the specified form is obtained.
/// Caller must free returned bytes.
pub fn decomposeTo(self: Self, allocator: *mem.Allocator, form: Form, dcs: []const Decomposed) anyerror![]const Decomposed {
    // Avoid recursive allocation hell with arena.
    var arena = std.heap.ArenaAllocator.init(allocator);
    defer arena.deinit();

    // Freed by arena.
    const rdcs = switch (form) {
        .D => try self.decompD(&arena.allocator, dcs),
        .KD => try self.decompKD(&arena.allocator, dcs),
    };

    // Freed by caller.
    var result = try allocator.alloc(Decomposed, rdcs.len);
    mem.copy(Decomposed, result, rdcs);

    return result;
}

fn decompD(self: Self, allocator: *mem.Allocator, dcs: []const Decomposed) anyerror![]const Decomposed {
    // Base case;
    if (allDone(dcs)) return dcs;

    var rdcs = std.ArrayList(Decomposed).init(allocator);
    defer rdcs.deinit();

    for (dcs) |dc| {
        switch (dc) {
            .src => |cp| {
                const m = try self.mapping(cp);
                switch (m) {
                    .same, .compat => {
                        try rdcs.append(.{ .same = cp });
                        return rdcs.toOwnedSlice();
                    },
                    else => {
                        try rdcs.appendSlice(try self.decomposeTo(allocator, .D, &[_]Decomposed{m}));
                    },
                }
            },
            .same => try rdcs.append(dc),
            .single => |cp| if (self.nfd_check.isNFD(cp)) {
                try rdcs.append(.{ .same = cp });
            } else {
                const m = try self.mapping(cp);
                switch (m) {
                    .same, .compat => try rdcs.append(.{ .same = cp }),
                    else => try rdcs.appendSlice(try self.decomposeTo(allocator, .D, &[_]Decomposed{m})),
                }
            },
            .canon => |seq| {
                for (seq) |cp| {
                    if (self.nfd_check.isNFD(cp)) {
                        try rdcs.append(.{ .same = cp });
                    } else {
                        const m = try self.mapping(cp);
                        switch (m) {
                            .same, .compat => try rdcs.append(.{ .same = cp }),
                            else => try rdcs.appendSlice(try self.decomposeTo(allocator, .D, &[_]Decomposed{m})),
                        }
                    }
                }
            },
            .compat => {},
        }
    }

    return rdcs.toOwnedSlice();
}

fn decompKD(self: Self, allocator: *mem.Allocator, dcs: []const Decomposed) anyerror![]const Decomposed {
    // Base case;
    if (allDone(dcs)) return dcs;

    var rdcs = std.ArrayList(Decomposed).init(allocator);
    defer rdcs.deinit();

    for (dcs) |dc| {
        switch (dc) {
            .src => |cp| {
                const m = [1]Decomposed{try self.mapping(cp)};
                try rdcs.appendSlice(try self.decomposeTo(allocator, .KD, &m));
            },
            .same => try rdcs.append(dc),
            .single => |cp| {
                const m = [1]Decomposed{try self.mapping(cp)};
                try rdcs.appendSlice(try self.decomposeTo(allocator, .KD, &m));
            },
            .canon => |seq| {
                for (seq) |cp| {
                    const m = [1]Decomposed{try self.mapping(cp)};
                    try rdcs.appendSlice(try self.decomposeTo(allocator, .KD, &m));
                }
            },
            .compat => |seq| {
                for (seq) |cp| {
                    const m = [1]Decomposed{try self.mapping(cp)};
                    try rdcs.appendSlice(try self.decomposeTo(allocator, .KD, &m));
                }
            },
        }
    }

    return rdcs.toOwnedSlice();
}

fn finalizeAndEncode(self: Self, allocator: *mem.Allocator, code_points: []u21) ![]u8 {
    var result = std.ArrayList(u8).init(allocator);
    defer result.deinit();

    // Apply canonical sort algorithm.
    self.canonicalSort(code_points);

    // Encode as UTF-8 code units.
    var buf: [4]u8 = undefined;
    for (code_points) |dcp| {
        const len = try unicode.utf8Encode(dcp, &buf);
        try result.appendSlice(buf[0..len]);
    }

    return result.toOwnedSlice();
}

/// normalizeTo will normalize the code points in str, producing a slice of u8 with the new bytes
/// corresponding to the specified Normalization Form. Caller must free returned bytes.
pub fn normalizeTo(self: Self, allocator: *mem.Allocator, form: Form, str: []const u8) anyerror![]u8 {
    // Gather source code points.
    var code_points = std.ArrayList(u21).init(allocator);
    defer code_points.deinit();

    var iter = (try unicode.Utf8View.init(str)).iterator();

    while (iter.nextCodepoint()) |cp| {
        try code_points.append(cp);
    }

    // NFD Quick Check.
    if (form == .D) {
        var already_nfd = true;

        for (code_points.items) |cp| {
            if (!self.nfd_check.isNFD(cp)) already_nfd = false;
        }

        // Already NFD, nothing more to do.
        if (already_nfd) return self.finalizeAndEncode(allocator, code_points.items);
    }

    var d_code_points = std.ArrayList(u21).init(allocator);
    defer d_code_points.deinit();

    // Gather decomposed code points.
    for (code_points.items) |cp| {
        const cp_slice = try self.codePointTo(allocator, form, cp);
        defer allocator.free(cp_slice);
        try d_code_points.appendSlice(cp_slice);
    }

    return self.finalizeAndEncode(allocator, d_code_points.items);
}

/// normalizeCodePointsTo will normalize the code points in str, producing a new slice of code points
/// corresponding to the specified Normalization Form. Caller must free returned bytes.
pub fn normalizeCodePointsTo(self: Self, allocator: *mem.Allocator, form: Form, str: []const u8) anyerror![]u21 {
    // Gather source code points.
    var code_points = std.ArrayList(u21).init(allocator);
    defer code_points.deinit();

    var iter = (try unicode.Utf8View.init(str)).iterator();

    while (iter.nextCodepoint()) |cp| {
        try code_points.append(cp);
    }

    // NFD Quick Check.
    if (form == .D) {
        var already_nfd = true;

        for (code_points.items) |cp| {
            if (!self.nfd_check.isNFD(cp)) already_nfd = false;
        }

        // Already NFD, nothing more to do.
        if (already_nfd) {
            // Apply canonical sort algorithm.
            self.canonicalSort(code_points.items);
            return code_points.toOwnedSlice();
        }
    }

    var d_code_points = std.ArrayList(u21).init(allocator);
    defer d_code_points.deinit();

    // Gather decomposed code points.
    for (code_points.items) |cp| {
        const cp_slice = try self.codePointTo(allocator, form, cp);
        defer allocator.free(cp_slice);
        try d_code_points.appendSlice(cp_slice);
    }

    // Apply canonical sort algorithm.
    self.canonicalSort(d_code_points.items);
    return d_code_points.toOwnedSlice();
}

fn cccLess(self: Self, lhs: u21, rhs: u21) bool {
    return self.ccc_map.combiningClass(lhs) < self.ccc_map.combiningClass(rhs);
}

fn canonicalSort(self: Self, cp_list: []u21) void {
    var i: usize = 0;
    while (true) {
        if (i >= cp_list.len) break;
        var start: usize = i;
        while (i < cp_list.len and self.ccc_map.combiningClass(cp_list[i]) != 0) : (i += 1) {}
        sort(u21, cp_list[start..i], self, cccLess);
        i += 1;
    }
}

fn decomposeHangul(self: Self, cp: u21) [3]u21 {
    const SBase: u21 = 0xAC00;
    const LBase: u21 = 0x1100;
    const VBase: u21 = 0x1161;
    const TBase: u21 = 0x11A7;
    const LCount: u21 = 19;
    const VCount: u21 = 21;
    const TCount: u21 = 28;
    const NCount: u21 = 588; // VCount * TCount
    const SCount: u21 = 11172; // LCount * NCount

    const SIndex: u21 = cp - SBase;
    const LIndex: u21 = SIndex / NCount;
    const VIndex: u21 = (SIndex % NCount) / TCount;
    const TIndex: u21 = SIndex % TCount;
    const LPart: u21 = LBase + LIndex;
    const VPart: u21 = VBase + VIndex;
    var TPart: u21 = 0;
    if (TIndex != 0) TPart = TBase + TIndex;

    return [3]u21{ LPart, VPart, TPart };
}

fn isHangulPrecomposed(self: Self, cp: u21) bool {
    if (self.hangul_map.syllableType(cp)) |kind| {
        return switch (kind) {
            .LV, .LVT => true,
            else => false,
        };
    } else {
        return false;
    }
}

fn allDone(dcs: []const Decomposed) bool {
    for (dcs) |dc| {
        if (dc != .same) return false;
    }
    return true;
}

/// CmpMode determines the type of comparison to be performed.
/// * ignore_case compares ignoring letter case.
/// * normalize compares the result of normalizing to canonical form (NFD).
/// * norm_ignore combines both ignore_case and normalize modes.
pub const CmpMode = enum {
    ignore_case,
    normalize,
    norm_ignore,
};

/// eqlBy compares for equality between `a` and `b` according to the specified comparison mode.
pub fn eqlBy(self: Self, a: []const u8, b: []const u8, mode: CmpMode) !bool {
    // Check for ASCII only comparison.
    var ascii_only = try isAsciiStr(a);

    if (ascii_only) {
        ascii_only = try isAsciiStr(b);
    }

    // If ASCII only, different lengths mean inequality.
    const len_a = a.len;
    const len_b = b.len;
    var len_eql = len_a == len_b;

    if (ascii_only and !len_eql) return false;

    if (mode == .ignore_case and len_eql) {
        if (ascii_only) {
            // ASCII case insensitive.
            for (a) |c, i| {
                const oc = b[i];
                const lc = if (c >= 'A' and c <= 'Z') c ^ 32 else c;
                const olc = if (oc >= 'A' and oc <= 'Z') oc ^ 32 else oc;
                if (lc != olc) return false;
            }
            return true;
        }

        // Non-ASCII case insensitive.
        return self.eqlIgnoreCase(a, b);
    }

    if (mode == .normalize) return self.eqlNorm(a, b);
    if (mode == .norm_ignore) return self.eqlNormIgnore(a, b);

    return false;
}

fn eqlIgnoreCase(self: Self, a: []const u8, b: []const u8) !bool {
    const cf_a = try self.fold_map.caseFoldStr(self.allocator, a);
    defer self.allocator.free(cf_a);
    const cf_b = try self.fold_map.caseFoldStr(self.allocator, b);
    defer self.allocator.free(cf_b);

    return mem.eql(u8, cf_a, cf_b);
}

fn eqlNorm(self: Self, a: []const u8, b: []const u8) !bool {
    var arena = std.heap.ArenaAllocator.init(self.allocator);
    defer arena.deinit();

    const norm_a = try self.normalizeTo(&arena.allocator, .D, a);
    const norm_b = try self.normalizeTo(&arena.allocator, .D, b);

    return mem.eql(u8, norm_a, norm_b);
}

fn eqlNormIgnore(self: Self, a: []const u8, b: []const u8) !bool {
    var arena = std.heap.ArenaAllocator.init(self.allocator);
    defer arena.deinit();

    // The long winding road of normalized caseless matching...
    // NFD(CaseFold(NFD(str)))
    var norm_a = try self.normalizeTo(&arena.allocator, .D, a);
    var cf_a = try self.fold_map.caseFoldStr(&arena.allocator, norm_a);
    norm_a = try self.normalizeTo(&arena.allocator, .D, cf_a);
    var norm_b = try self.normalizeTo(&arena.allocator, .D, b);
    var cf_b = try self.fold_map.caseFoldStr(&arena.allocator, norm_b);
    norm_b = try self.normalizeTo(&arena.allocator, .D, cf_b);

    return mem.eql(u8, norm_a, norm_b);
}

/// isAsciiStr checks if a string (`[]const uu`) is composed solely of ASCII characters.
fn isAsciiStr(str: []const u8) !bool {
    // Shamelessly stolen from std.unicode.
    const N = @sizeOf(usize);
    const MASK = 0x80 * (std.math.maxInt(usize) / 0xff);

    var i: usize = 0;
    while (i < str.len) {
        // Fast path for ASCII sequences
        while (i + N <= str.len) : (i += N) {
            const v = mem.readIntNative(usize, str[i..][0..N]);
            if (v & MASK != 0) {
                return false;
            }
        }

        if (i < str.len) {
            const n = try unicode.utf8ByteSequenceLength(str[i]);
            if (i + n > str.len) return error.TruncatedInput;

            switch (n) {
                1 => {}, // ASCII
                else => return false,
            }

            i += n;
        }
    }

    return true;
}

test "Normalizer codePointTo D" {
    var allocator = std.testing.allocator;
    var normalizer = try init(allocator, "src/data/ucd/UnicodeData.txt");
    defer normalizer.deinit();

    var result = try normalizer.codePointTo(allocator, .D, '\u{00E9}');
    defer allocator.free(result);
    try std.testing.expectEqualSlices(u21, result, &[2]u21{ 0x0065, 0x0301 });
    allocator.free(result);

    result = try normalizer.codePointTo(allocator, .D, '\u{03D3}');
    try std.testing.expectEqualSlices(u21, result, &[2]u21{ 0x03D2, 0x0301 });
}

test "Normalizer codePointTo KD" {
    var allocator = std.testing.allocator;
    var normalizer = try init(allocator, "src/data/ucd/UnicodeData.txt");
    defer normalizer.deinit();

    var result = try normalizer.codePointTo(allocator, .KD, '\u{00E9}');
    defer allocator.free(result);
    try std.testing.expectEqualSlices(u21, result, &[2]u21{ 0x0065, 0x0301 });
    allocator.free(result);

    result = try normalizer.codePointTo(allocator, .KD, '\u{03D3}');
    try std.testing.expectEqualSlices(u21, result, &[2]u21{ 0x03A5, 0x0301 });
}

test "Normalizer normalizeTo" {
    var allocator = std.testing.allocator;
    var normalizer = try init(allocator, "src/data/ucd/UnicodeData.txt");
    defer normalizer.deinit();

    var file = try std.fs.cwd().openFile("src/data/ucd/NormalizationTest.txt", .{});
    defer file.close();
    var buf_reader = std.io.bufferedReader(file.reader());
    var input_stream = buf_reader.reader();
    var buf: [640]u8 = undefined;
    while (try input_stream.readUntilDelimiterOrEof(&buf, '\n')) |line| {
        // Skip comments or empty lines.
        if (line.len == 0 or line[0] == '#' or line[0] == '@') continue;
        // Iterate over fields.
        var fields = mem.split(line, ";");
        var field_index: usize = 0;
        var input: []u8 = undefined;
        defer allocator.free(input);
        while (fields.next()) |field| : (field_index += 1) {
            if (field_index == 0) {
                var i_buf = std.ArrayList(u8).init(allocator);
                defer i_buf.deinit();
                var i_fields = mem.split(field, " ");
                while (i_fields.next()) |s| {
                    const icp = try std.fmt.parseInt(u21, s, 16);
                    const len = try unicode.utf8Encode(icp, &cp_buf);
                    try i_buf.appendSlice(cp_buf[0..len]);
                }
                input = i_buf.toOwnedSlice();
            } else if (field_index == 2) {
                // NFD, time to test.
                var w_buf = std.ArrayList(u8).init(allocator);
                defer w_buf.deinit();
                var w_fields = mem.split(field, " ");
                while (w_fields.next()) |s| {
                    const wcp = try std.fmt.parseInt(u21, s, 16);
                    const len = try unicode.utf8Encode(wcp, &cp_buf);
                    try w_buf.appendSlice(cp_buf[0..len]);
                }
                const want = w_buf.toOwnedSlice();
                defer allocator.free(want);
                const got = try normalizer.normalizeTo(allocator, .D, input);
                defer allocator.free(got);
                try std.testing.expectEqualSlices(u8, want, got);
                continue;
            } else if (field_index == 4) {
                // NFKD, time to test.
                var w_buf = std.ArrayList(u8).init(allocator);
                defer w_buf.deinit();
                var w_fields = mem.split(field, " ");
                while (w_fields.next()) |s| {
                    const wcp = try std.fmt.parseInt(u21, s, 16);
                    const len = try unicode.utf8Encode(wcp, &cp_buf);
                    try w_buf.appendSlice(cp_buf[0..len]);
                }
                const want = w_buf.toOwnedSlice();
                defer allocator.free(want);
                const got = try normalizer.normalizeTo(allocator, .KD, input);
                defer allocator.free(got);
                try std.testing.expectEqualSlices(u8, want, got);
                continue;
            } else {
                continue;
            }
        }
    }
}

test "Normalizer eqlBy" {
    var allocator = std.testing.allocator;
    var normalizer = try init(allocator, "src/data/ucd/UnicodeData.txt");
    defer normalizer.deinit();

    try std.testing.expect(try normalizer.eqlBy("foé", "foe\u{0301}", .normalize));
    try std.testing.expect(try normalizer.eqlBy("foϓ", "fo\u{03D2}\u{0301}", .normalize));
    try std.testing.expect(try normalizer.eqlBy("Foϓ", "fo\u{03D2}\u{0301}", .norm_ignore));
    try std.testing.expect(try normalizer.eqlBy("FOÉ", "foe\u{0301}", .norm_ignore)); // foÉ == foé
}
