}

var utf8_buf: [4]u8 = undefined;

/// mapping retrieves the decomposition mapping for a code point as per the UCD.
pub fn mapping(self: Self, cp: u21) !Decomposed {
    const len = try unicode.utf8Encode(cp, &utf8_buf);
    const lookup = self.decomp_trie.find(utf8_buf[0..len]);
    if (lookup.value) |value| if (lookup.index + 1 == len) return value;
    return Decomposed{ .same = cp };
}

pub const Form = enum {
    D, // Canonical Decomposition
    KD, // Compatibility Decomposition
};

/// codePointTo takes a code point and returns a sequence of code points that represent its conversion 
/// to the specified Form. Caller must free returned bytes.
pub fn codePointTo(self: Self, allocator: *mem.Allocator, form: Form, cp: u21) anyerror![]u21 {
    if (form == .D or form == .KD) {
        // Decomposition.
        if (self.isHangulPrecomposed(cp)) {
            // Hangul precomposed syllable full decomposition.
            const dcs = self.decomposeHangul(cp);
            const len: usize = if (dcs[2] == 0) 2 else 3;
            var result = try allocator.alloc(u21, len);
            mem.copy(u21, result, dcs[0..len]);
            return result;
        } else {
            // Non-Hangul code points.
            const src = [1]Decomposed{.{ .src = cp }};
            const dcs = try self.decomposeTo(allocator, form, &src);
            defer allocator.free(dcs);
            var result = try allocator.alloc(u21, dcs.len);
            for (dcs) |dc, index| {
                result[index] = dc.same;
            }
            return result;
        }
    } else {
        return error.FormUnimplemented;
    }
}

/// decomposeTo recursively performs decomposition until the specified form is obtained.
/// Caller must free returned bytes.
pub fn decomposeTo(self: Self, allocator: *mem.Allocator, form: Form, dcs: []const Decomposed) anyerror![]const Decomposed {
    // Avoid recursive allocation hell with arena.
    var arena = std.heap.ArenaAllocator.init(allocator);
    defer arena.deinit();

    // Freed by arena.
    const rdcs = switch (form) {
        .D => try self.decompD(&arena.allocator, dcs),
        .KD => try self.decompKD(&arena.allocator, dcs),
    };

    // Freed by caller.
    var result = try allocator.alloc(Decomposed, rdcs.len);
    for (rdcs) |dc, i| {
        result[i] = dc;
    }

    return result;
}

fn decompD(self: Self, allocator: *mem.Allocator, dcs: []const Decomposed) anyerror![]const Decomposed {
    // Base case;
    if (allDone(dcs)) return dcs;

    var rdcs = std.ArrayList(Decomposed).init(allocator);
    defer rdcs.deinit();

    for (dcs) |dc| {
        switch (dc) {
            .src => |cp| {
                const next_map = try self.mapping(cp);
                if (next_map == .same) {
                    try rdcs.append(next_map);
                    return rdcs.toOwnedSlice();
                } else if (next_map == .compat) {
                    try rdcs.append(.{ .same = cp });
                    return rdcs.toOwnedSlice();
                } else {
                    const m = [1]Decomposed{try self.mapping(cp)};
                    try rdcs.appendSlice(try self.decomposeTo(allocator, .D, &m));
                }
            },
            .same => try rdcs.append(dc),
            .single => |cp| {
                const next_map = try self.mapping(cp);
                if (next_map == .same or next_map == .compat) {
                    try rdcs.append(.{ .same = cp });
                } else {
                    const m = [1]Decomposed{try self.mapping(cp)};
                    try rdcs.appendSlice(try self.decomposeTo(allocator, .D, &m));
                }
            },
            .canon => |seq| {
                for (seq) |cp| {
                    const next_map = try self.mapping(cp);
                    if (next_map == .same or next_map == .compat) {
                        try rdcs.append(.{ .same = cp });
                    } else {
                        const m = [1]Decomposed{next_map};
                        try rdcs.appendSlice(try self.decomposeTo(allocator, .D, &m));
                    }
                }
            },
            .compat => {},
        }
    }

    return rdcs.toOwnedSlice();
}

fn decompKD(self: Self, allocator: *mem.Allocator, dcs: []const Decomposed) anyerror![]const Decomposed {
    // Base case;
    if (allDone(dcs)) return dcs;

    var rdcs = std.ArrayList(Decomposed).init(allocator);
    defer rdcs.deinit();

    for (dcs) |dc| {
        switch (dc) {
            .src => |cp| {
                const m = [1]Decomposed{try self.mapping(cp)};
                try rdcs.appendSlice(try self.decomposeTo(allocator, .KD, &m));
            },
            .same => try rdcs.append(dc),
            .single => |cp| {
                const m = [1]Decomposed{try self.mapping(cp)};
                try rdcs.appendSlice(try self.decomposeTo(allocator, .KD, &m));
            },
            .canon => |seq| {
                for (seq) |cp| {
                    const m = [1]Decomposed{try self.mapping(cp)};
                    try rdcs.appendSlice(try self.decomposeTo(allocator, .KD, &m));
                }
            },
            .compat => |seq| {
                for (seq) |cp| {
                    const m = [1]Decomposed{try self.mapping(cp)};
                    try rdcs.appendSlice(try self.decomposeTo(allocator, .KD, &m));
                }
            },
        }
    }

    return rdcs.toOwnedSlice();
}

fn finalizeAndEncode(self: Self, allocator: *mem.Allocator, code_points: []u21) ![]u8 {
    var result = std.ArrayList(u8).init(allocator);
    defer result.deinit();

    // Apply canonical sort algorithm.
    self.canonicalSort(code_points);

    // Encode as UTF-8 code units.
    var buf: [4]u8 = undefined;
    for (code_points) |dcp| {
        const len = try unicode.utf8Encode(dcp, &buf);
        try result.appendSlice(buf[0..len]);
    }

    return result.toOwnedSlice();
}

/// normalizeTo will normalize the code points in str, producing a slice of u8 with the new bytes
/// corresponding to the specified Normalization Form. Caller must free returned bytes.
pub fn normalizeTo(self: Self, allocator: *mem.Allocator, form: Form, str: []const u8) anyerror![]u8 {
    if (form != .D and form != .KD) return error.FormUnimplemented;

    // Gather source code points.
    var code_points = std.ArrayList(u21).init(allocator);
    defer code_points.deinit();

    var iter = (try unicode.Utf8View.init(str)).iterator();

    while (iter.nextCodepoint()) |cp| {
        try code_points.append(cp);
    }

    // NFD Quick Check.
    if (form == .D) {
        var already_nfd = true;

        for (code_points.items) |cp| {
            if (!self.nfd_check.isNFD(cp)) already_nfd = false;
        }

        // Already NFD, nothing more to do.
        if (already_nfd) return self.finalizeAndEncode(allocator, code_points.items);
    }

    var d_code_points = std.ArrayList(u21).init(allocator);
    defer d_code_points.deinit();

    // Gather decomposed code points.
    for (code_points.items) |cp| {
        const cp_slice = try self.codePointTo(allocator, form, cp);
        defer allocator.free(cp_slice);
        try d_code_points.appendSlice(cp_slice);
    }

    return self.finalizeAndEncode(allocator, d_code_points.items);
}

/// normalizeCodePointsTo will normalize the code points in str, producing a new slice of code points
/// corresponding to the specified Normalization Form. Caller must free returned bytes.
pub fn normalizeCodePointsTo(self: *Self, allocator: *mem.Allocator, form: Form, str: []const u8) anyerror![]u21 {
    if (form != .D and form != .KD) return error.FormUnimplemented;

    // Gather source code points.
    var code_points = std.ArrayList(u21).init(allocator);
    defer code_points.deinit();

    var iter = (try unicode.Utf8View.init(str)).iterator();

    while (iter.nextCodepoint()) |cp| {
        try code_points.append(cp);
    }

    // NFD Quick Check.
    if (form == .D) {
        var already_nfd = true;

        for (code_points.items) |cp| {
            if (!self.nfd_check.isNFD(cp)) already_nfd = false;
        }

        // Already NFD, nothing more to do.
        if (already_nfd) {
            // Apply canonical sort algorithm.
            self.canonicalSort(code_points.items);
            return code_points.toOwnedSlice();
        }
    }

    var d_code_points = std.ArrayList(u21).init(allocator);
    defer d_code_points.deinit();

    // Gather decomposed code points.
    for (code_points.items) |cp| {
        const cp_slice = try self.codePointTo(allocator, form, cp);
        defer allocator.free(cp_slice);
        try d_code_points.appendSlice(cp_slice);
    }

    // Apply canonical sort algorithm.
    self.canonicalSort(d_code_points.items);
    return d_code_points.toOwnedSlice();
}

fn cccLess(self: Self, lhs: u21, rhs: u21) bool {
    return self.ccc_map.combiningClass(lhs) < self.ccc_map.combiningClass(rhs);
}

fn canonicalSort(self: Self, cp_list: []u21) void {
    var i: usize = 0;
    while (true) {
        if (i >= cp_list.len) break;
        var start: usize = i;
        while (i < cp_list.len and self.ccc_map.combiningClass(cp_list[i]) != 0) : (i += 1) {}
        sort(u21, cp_list[start..i], self, cccLess);
        i += 1;
    }
}

fn decomposeHangul(self: Self, cp: u21) [3]u21 {
    const SBase: u21 = 0xAC00;
    const LBase: u21 = 0x1100;
    const VBase: u21 = 0x1161;
    const TBase: u21 = 0x11A7;
    const LCount: u21 = 19;
    const VCount: u21 = 21;
    const TCount: u21 = 28;
    const NCount: u21 = 588; // VCount * TCount
    const SCount: u21 = 11172; // LCount * NCount

    const SIndex: u21 = cp - SBase;
    const LIndex: u21 = SIndex / NCount;
    const VIndex: u21 = (SIndex % NCount) / TCount;
    const TIndex: u21 = SIndex % TCount;
    const LPart: u21 = LBase + LIndex;
    const VPart: u21 = VBase + VIndex;
    var TPart: u21 = 0;
    if (TIndex != 0) TPart = TBase + TIndex;

    return [3]u21{ LPart, VPart, TPart };
}

fn isHangulPrecomposed(self: Self, cp: u21) bool {
    if (self.hangul_map.syllableType(cp)) |kind| {
        return switch (kind) {
            .LV, .LVT => true,
            else => false,
        };
    } else {
        return false;
    }
}

fn allDone(dcs: []const Decomposed) bool {
    for (dcs) |dc| {
        if (dc != .same) return false;
    }
    return true;
}

/// CmpMode determines the type of comparison to be performed.
/// * ignore_case compares ignoring letter case.
/// * normalize compares the result of normalizing to canonical form (NFD).
/// * norm_ignore combines both ignore_case and normalize modes.
pub const CmpMode = enum {
    ignore_case,
    normalize,
    norm_ignore,
};

/// eqlBy compares for equality between `a` and `b` according to the specified comparison mode.
pub fn eqlBy(self: Self, a: []const u8, b: []const u8, mode: CmpMode) !bool {
    // Check for ASCII only comparison.
    var ascii_only = try isAsciiStr(a);

    if (ascii_only) {
        ascii_only = try isAsciiStr(b);
    }

    // If ASCII only, different lengths mean inequality.
    const len_a = a.len;
    const len_b = b.len;
    var len_eql = len_a == len_b;

    if (ascii_only and !len_eql) return false;

    if (mode == .ignore_case and len_eql) {
        if (ascii_only) {
            // ASCII case insensitive.
            for (a) |c, i| {
                const oc = b[i];
                const lc = if (c >= 'A' and c <= 'Z') c ^ 32 else c;
                const olc = if (oc >= 'A' and oc <= 'Z') oc ^ 32 else oc;
                if (lc != olc) return false;
            }
            return true;
        }

        // Non-ASCII case insensitive.
        return self.eqlIgnoreCase(a, b);
    }

    if (mode == .normalize) return self.eqlNorm(a, b);
    if (mode == .norm_ignore) return self.eqlNormIgnore(a, b);

    return false;
}

fn eqlIgnoreCase(self: Self, a: []const u8, b: []const u8) !bool {
    const cf_a = try self.letter.fold_map.caseFoldStr(self.allocator, a);
    defer self.allocator.free(cf_a);
    const cf_b = try self.letter.fold_map.caseFoldStr(self.allocator, b);
    defer self.allocator.free(cf_b);

    return mem.eql(u8, cf_a, cf_b);
}

fn eqlNorm(self: Self, a: []const u8, b: []const u8) !bool {
    var arena = std.heap.ArenaAllocator.init(self.allocator);
    defer arena.deinit();

    const norm_a = try self.normalizeTo(&arena.allocator, .D, a);
    const norm_b = try self.normalizeTo(&arena.allocator, .D, b);

    return mem.eql(u8, norm_a, norm_b);
}

fn eqlNormIgnore(self: Self, a: []const u8, b: []const u8) !bool {
    var arena = std.heap.ArenaAllocator.init(self.allocator);
    defer arena.deinit();

    // The long winding road of normalized caseless matching...
    // NFD(CaseFold(NFD(str)))
    var norm_a = try self.normalizeTo(&arena.allocator, .D, a);
    var cf_a = try self.letter.fold_map.caseFoldStr(&arena.allocator, norm_a);
    norm_a = try self.normalizeTo(&arena.allocator, .D, cf_a);
    var norm_b = try self.normalizeTo(&arena.allocator, .D, b);
    var cf_b = try self.letter.fold_map.caseFoldStr(&arena.allocator, norm_b);
    norm_b = try self.normalizeTo(&arena.allocator, .D, cf_b);

    return mem.eql(u8, norm_a, norm_b);
}

/// isAsciiStr checks if a string (`[]const uu`) is composed solely of ASCII characters.
fn isAsciiStr(str: []const u8) !bool {
    // Shamelessly stolen from std.unicode.
    const N = @sizeOf(usize);
    const MASK = 0x80 * (std.math.maxInt(usize) / 0xff);

    var i: usize = 0;
    while (i < str.len) {
        // Fast path for ASCII sequences
        while (i + N <= str.len) : (i += N) {
            const v = mem.readIntNative(usize, str[i..][0..N]);
            if (v & MASK != 0) {
                return false;
            }
        }

        if (i < str.len) {
            const n = try unicode.utf8ByteSequenceLength(str[i]);
            if (i + n > str.len) return error.TruncatedInput;

            switch (n) {
                1 => {}, // ASCII
                else => return false,
            }

            i += n;
        }
    }

    return true;
}

test "Normalizer codePointTo D" {
    var allocator = std.testing.allocator;
    var normalizer = try init(allocator);
    defer normalizer.deinit();

    var result = try normalizer.codePointTo(allocator, .D, '\u{00E9}');
    defer allocator.free(result);
    std.testing.expectEqualSlices(u21, result, &[2]u21{ 0x0065, 0x0301 });
    allocator.free(result);

    result = try normalizer.codePointTo(allocator, .D, '\u{03D3}');
    std.testing.expectEqualSlices(u21, result, &[2]u21{ 0x03D2, 0x0301 });
}

test "Normalizer codePointTo KD" {
    var allocator = std.testing.allocator;
    var normalizer = try init(allocator);
    defer normalizer.deinit();

    var result = try normalizer.codePointTo(allocator, .KD, '\u{00E9}');
    defer allocator.free(result);
    std.testing.expectEqualSlices(u21, result, &[2]u21{ 0x0065, 0x0301 });
    allocator.free(result);

    result = try normalizer.codePointTo(allocator, .KD, '\u{03D3}');
    std.testing.expectEqualSlices(u21, result, &[2]u21{ 0x03A5, 0x0301 });
}

test "Normalizer normalizeTo" {
    var allocator = std.testing.allocator;
    var normalizer = try init(allocator);
    defer normalizer.deinit();

    var file = try std.fs.cwd().openFile("src/data/ucd/NormalizationTest.txt", .{});
    defer file.close();
    var buf_reader = std.io.bufferedReader(file.reader());
    var input_stream = buf_reader.reader();
    var buf: [640]u8 = undefined;
    while (try input_stream.readUntilDelimiterOrEof(&buf, '\n')) |line| {
        // Skip comments or empty lines.
        if (line.len == 0 or line[0] == '#' or line[0] == '@') continue;
        // Iterate over fields.
        var fields = mem.split(line, ";");
        var field_index: usize = 0;
        var input: []u8 = undefined;
        defer allocator.free(input);
        while (fields.next()) |field| : (field_index += 1) {
            if (field_index == 0) {
                var i_buf = std.ArrayList(u8).init(allocator);
                defer i_buf.deinit();
                var i_fields = mem.split(field, " ");
                var cp_buf: [4]u8 = undefined;
                while (i_fields.next()) |s| {
                    const icp = try std.fmt.parseInt(u21, s, 16);
                    const len = try unicode.utf8Encode(icp, &cp_buf);
                    try i_buf.appendSlice(cp_buf[0..len]);
                }
                input = i_buf.toOwnedSlice();
            } else if (field_index == 2) {
                // NFD, time to test.
                var w_buf = std.ArrayList(u8).init(allocator);
                defer w_buf.deinit();
                var w_fields = mem.split(field, " ");
                var cp_buf: [4]u8 = undefined;
                while (w_fields.next()) |s| {
                    const wcp = try std.fmt.parseInt(u21, s, 16);
                    const len = try unicode.utf8Encode(wcp, &cp_buf);
                    try w_buf.appendSlice(cp_buf[0..len]);
                }
                const want = w_buf.toOwnedSlice();
                defer allocator.free(want);
                const got = try normalizer.normalizeTo(allocator, .D, input);
                defer allocator.free(got);
                std.testing.expectEqualSlices(u8, want, got);
                continue;
            } else if (field_index == 4) {
                // NFKD, time to test.
                var w_buf = std.ArrayList(u8).init(allocator);
                defer w_buf.deinit();
                var w_fields = mem.split(field, " ");
                var cp_buf: [4]u8 = undefined;
                while (w_fields.next()) |s| {
                    const wcp = try std.fmt.parseInt(u21, s, 16);
                    const len = try unicode.utf8Encode(wcp, &cp_buf);
                    try w_buf.appendSlice(cp_buf[0..len]);
                }
                const want = w_buf.toOwnedSlice();
                defer allocator.free(want);
                const got = try normalizer.normalizeTo(allocator, .KD, input);
                defer allocator.free(got);
                std.testing.expectEqualSlices(u8, want, got);
                continue;
            } else {
                continue;
            }
        }
    }
}

test "Normalizer eqlBy" {
    var normalizer = try init(std.testing.allocator);
    defer normalizer.deinit();

    std.testing.expect(try normalizer.eqlBy("foé", "foe\u{0301}", .normalize));
    std.testing.expect(try normalizer.eqlBy("foϓ", "fo\u{03D2}\u{0301}", .normalize));
    std.testing.expect(try normalizer.eqlBy("Foϓ", "fo\u{03D2}\u{0301}", .norm_ignore));
    std.testing.expect(try normalizer.eqlBy("FOÉ", "foe\u{0301}", .norm_ignore)); // foÉ == foé
}
